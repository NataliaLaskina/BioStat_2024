---
title: "automatization_notebook"
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(flextable)
library(rstatix)
library(corrplot)
library(psych)
library(ggcorrplot)
library(broom)
library(RColorBrewer)

################################################################################


get_cat_table <- function(factor_data, group_variable) {
  
  get_cat_table_one_variable <- function(factor_data, group_variable, variable_name) {
    
    factor_data %>%
      count(.data[[group_variable]], .data[[variable_name]], .drop = FALSE) %>%
      mutate(`Relative frequency` = (n / sum(n)) %>% round(4) %>% `*`(100) %>% str_c("%"),
      `95% CI` = {
      n_group <- sum(n) 
      p <- n / n_group
      paste0(
        scales::percent(p - 1.96 * sqrt(p * (1 - p) / n_group), accuracy = 0.01),
        " - ",
        scales::percent(p + 1.96 * sqrt(p * (1 - p) / n_group), accuracy = 0.01)
      )
    }
  ) %>%
      
      group_by(.data[[group_variable]]) %>%
      mutate(`Relative frequency by group` = (n / sum(n)) %>% round(4) %>% `*`(100) %>% str_c("%")) %>%
      ungroup() %>%
      
      rename(`Absolute frequency` = n) %>%
      mutate(`Chi-square test, p-value` = table(factor_data[[group_variable]], factor_data[[variable_name]]) %>% 
               chisq.test() %>% .$p.value %>% round(3),
             Variable = variable_name) %>%
      rename(Value := variable_name,
             Group := group_variable)
    
  }
  
  factor_data %>%
    select(!group_variable) %>%
    names() %>%
    map_dfr(function(variable_name) get_cat_table_one_variable(factor_data, group_variable, variable_name)) %>%
    select(Variable, Group, everything())
  
} 
```

# Чтение данных

В вашем варианте нужно использовать датасеты cardio_train_big или cardio_train_not_too_big.

```{r}

cardio <- read_delim("C:/Users/laskn/BioStat_2024/data/originals/cardio_train_big.csv", delim = ";", locale = locale(decimal_mark = "."))

#удалось прочитать данные только так, иначе значения weight читаются неадекватно (вместо 62.5 - 625)


```

# Выведите общее описание данных

```{r}

cardio %>%
  glimpse()

```

# Очистка данных

1)  Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

**Обоснование**: Я бы использовала оба варианта.Мы удаляем только те переменные и строки, которые содержат слишком много пропущенных значений и они могут исказить результаты анализа, как по отдельным переменным, так и по отдельным субъектам. Уменьшение размера датасета также может улучшить производительность при дальнейшем анализе данных.

2)  Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3)  В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4)  Отсортируйте данные по возрасту по убыванию;

5)  Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6)  Присвойте получившийся датасет переменной "cleaned_data".

```{r}

sum(is.na(cardio)) 

#Пропущенных значений в датасете нет, но если бы они были:

#cardio %>% select(where(~ mean(is.na(.x)) <= 0.2)) #Удаляем переменные с более 20% пропущенных значений
 
#cardio %>% filter(rowSums(is.na(.)) / ncol(.) <= 0.2) #Удаляем строки, в которых более 20% значений пропущены

```

```{r}

cardio %>%
    mutate(`Age (years)`  = round(age / 365.25, 1)) %>% 
    relocate(`Age (years)`, .after = age) %>% 
    rename(`Age (days)` = age) %>%    #решила пока оставить эту переменную, так как по ней точнее можно сортировать по возрасту, но воспринимать намного понятнее в годах
    rename(`Height (cm)` = height) %>%
    rename(`Weight (kg)` = weight) %>%
    rename(Gender = gender) %>% 
    rename(`Systolic blood pressure` = `ap_hi`) %>% 
    rename(`Diastolic blood pressure` = `ap_lo`) %>%
    rename(Cholesterol  = cholesterol ) %>%
    rename(Glucose = gluc)%>%
    rename(Smoking = smoke) %>% 
    rename(`Alcohol intake`= alco) %>%
    rename(`Physical activity` = active) %>%
    rename(`Cardiovascular disease` = cardio) %>%
    relocate(`Cardiovascular disease`, .after = id) %>% 
    
    mutate(
      across(Gender, function(x) x %>% factor(levels = c(1, 2), labels = c("Women", "Men"))), 
      across(c(Cholesterol, Glucose), function(x) x %>% factor(levels = c(1, 2, 3), labels = c("Normal", "Above normal", "Well above normal"))),
      across(c(Smoking, `Alcohol intake`, `Physical activity`, `Cardiovascular disease`), function(x) x %>% factor(levels = c(1, 0), labels = c("Yes", "No")))) %>% 
    arrange(desc(`Age (days)`)) -> cleaned_data

# Функция для определения выбросов по правилу трёх сигм
find_outliers <- function(x) {
  mean_x <- mean(x, na.rm = TRUE)
  sd_x <- sd(x, na.rm = TRUE)
  lower_bound <- mean_x - 3 * sd_x
  upper_bound <- mean_x + 3 * sd_x
  x[x < lower_bound | x > upper_bound]
}

# Поиск выбросов для выбранных переменных
outliers_data <- cleaned_data %>%
  mutate(
    across(c(`Height (cm)`, `Weight (kg)`, `Systolic blood pressure`, `Diastolic blood pressure`),
           ~ ifelse(.x %in% find_outliers(.x), .x, NA)
    )
  ) %>% 
  filter(!is.na(`Height (cm)`) | !is.na(`Weight (kg)`) | 
           !is.na(`Systolic blood pressure`) | 
           !is.na(`Diastolic blood pressure`)) 

# Сохранение в файл
write_csv(outliers_data, "outliers.csv")

#Так как в данных имеются выбросы - значения, сильно превосходящие физиологические возможности человека: отрицательное давление,или давление, измеряющееся в десятках тысяч, вес в 10 кг (при том, что все участники взрослые), и эти выбросы, явно внесенные по ошибке, сильно влияют на последующий анализ данных, решено их убрать и в датасете cleaned_data, заменив на пропущенные значения.

cleaned_data <- cleaned_data %>%
  mutate(
    across(c(`Height (cm)`, `Weight (kg)`, `Systolic blood pressure`, `Diastolic blood pressure`),
           ~ ifelse(.x %in% outliers_data[[cur_column()]], NA, .x)
    )
  )

```

## Снова пункт 1, но с дастасетом cleaned_data после замены в нем выбросов на NA

```{r}

cleaned_data <- cleaned_data %>%
  select(where(~ mean(is.na(.x)) <= 0.2)) %>% #Удаляем переменные с более 20% пропущенных значений
   filter(rowSums(is.na(.)) / ncol(.) <= 0.2) #Удаляем строки, в которых более 20% значений пропущены

```

# Сколько осталось переменных?

```{r}

ncol(cleaned_data)

```

# Сколько осталось случаев?

```{r}

nrow(cleaned_data)

```

# Есть ли в данных идентичные строки?

```{r}

any(duplicated(cleaned_data))
anyDuplicated(cleaned_data)

```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}

NA_vars <- names(cleaned_data)[sapply(cleaned_data, function(x) any(is.na(x)))] 
sapply(cleaned_data[NA_vars], function(x) sum(is.na(x)))%>%
enframe() %>%
  rename(`NA count` = value) %>%
  rename(`Variable` = name)

```

# Описательные статистики

## Количественные переменные

1)  Рассчитайте для всех количественных переменных для каждой группы (наличие или отсутствие сердечно-сосудистых заболеваний):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
statistics <- list(
  
	      `_Количество субъектов` = ~length(.x) %>% as.character(),
	      `_Количество (есть данные)` = ~sum(!is.na(.x)) %>% as.character(),
	      `_Нет данных` = ~sum(is.na(.x)) %>% as.character(),
	      `_Ср. знач.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
	      `_Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
	      `_95% ДИ для среднего` = ~{
    n <- sum(!is.na(.x))
    ifelse(n < 3, "Н/П*", 
           paste0(round(mean(.x, na.rm = TRUE) - 1.96 * sd(.x, na.rm = TRUE) / sqrt(n), 2), " - ", round(mean(.x, na.rm = TRUE) + 1.96 * sd(.x, na.rm = TRUE) / sqrt(n), 2))
    )
  },
	      `_мин. - макс.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(min(.x, na.rm = TRUE) %>% round(2), " - ", max(.x, na.rm = TRUE) %>% round(2))),
	      `_Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
	      `_Q1 - Q3` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2), " - ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2)))
	)

cleaned_data %>% 
  select(`Cardiovascular disease`, where(is.numeric) & !id, -`Age (days)`)  %>% 
  group_by(`Cardiovascular disease`) %>% 
  summarize(across(where(is.numeric), statistics)) %>%
  pivot_longer(!`Cardiovascular disease`) %>%
  separate(name, into = c("Variable", "Statistics"), sep = "__") %>% 
  rename(Value = value) %>%
  flextable() %>%
  theme_box() %>%
  align(align = "center", part = "all") %>% 
  merge_v(c("Cardiovascular disease", "Variable"))

```

## Категориальные переменные

1)  Рассчитайте для всех категориальных переменных для каждой группы (наличие или отсутствие сердечно-сосудистых заболеваний):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}

#я не смогла завставить тест Фишера работать на таком большом датасете, использую Хи-квадрат
 
cleaned_data %>%
  select(where(is.factor)) -> factor_data

get_cat_table(factor_data, "Cardiovascular disease") %>%
  rename(`Cardiovascular disease` = Group) %>%
  flextable() %>%
  theme_box() %>%
  align(align = "center", part = "all") %>%
  merge_v(c("Cardiovascular disease", "Variable")) %>%
  merge_v("Variable", target = "Chi-square test, p-value")

```

# Визуализация

## Количественные переменные

1)  Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2)  Наложите на боксплоты beeplots - задание со звёздочкой.

3)  Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r}

theme_custom <- theme(
    axis.text = element_text(size = 18),
    axis.title = element_text(size = 20),
    plot.title = element_text(size = 24, hjust = 0.5),
     legend.position = "none"
  )

quant_vars <- names(cleaned_data)[sapply(cleaned_data, is.numeric) & 
                                 !names(cleaned_data) %in% c("id", "Age (days)")]


create_boxplot <- function(var_name) {
  ggplot(cleaned_data, aes(x = `Cardiovascular disease`, y = !!sym(var_name), fill = `Cardiovascular disease`)) +
    geom_jitter(
              colour = "gray40",
              size = 0.5,
              width =0.4, 
              alpha = 0.7, na.rm = TRUE  
             ) +
    geom_boxplot(colour = "black", fatten = 2, na.rm = TRUE, outlier.shape = NA) +
    scale_fill_brewer(palette = "Set1") +
    labs(title = paste0("Boxplot for ", var_name),
         x = "Cardiovascular Disease",
         y = var_name) +
    theme_bw()+
    theme_custom
}

lapply(quant_vars, create_boxplot)

```

Несмотря на то, что из датасета были удалены выбросы за передлами трех сигм, все равно остались значения, вряд ли адекватные и, вероятно, связанные с ошибкой ввода (особенно это видно по показателям давления).


## Категориальные переменные

1)  Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}

theme_custom_2 <- theme(
    axis.text = element_text(size = 16),
    axis.text.x = element_text(angle = 10, hjust = 1),
    axis.title = element_text(size = 20),
    plot.title = element_text(size = 24, hjust = 0.5),
    legend.title = element_text(size = 18),
    legend.text = element_text(size = 16)
  )


cat_vars <- names(cleaned_data)[sapply(cleaned_data, is.factor)]

create_bar_plot <- function(var_name) {
  ggplot(cleaned_data, aes(x = !!sym(var_name), fill = `Cardiovascular disease`)) +
    geom_bar(position = "dodge") +  
    labs(title = paste0("Bar Plot for ", var_name),
         x = var_name,
         y = "Count",
         fill = "Cardiovascular Disease") +
    theme_bw()+
    theme_custom_2
}

lapply(cat_vars, create_bar_plot)

```

Geom_bar строит столбчатую диаграмму, где высота каждого столбца представляет количество наблюдений в каждой категории.

Преимущества такого способа визуализации категориальной переменной:
 Простой и интуитивно понятный способ визуализации категориальных данных.
 Хорошо подходит для сравнения частот между категориями.
 Можно использовать для визуализации соотношения одной категориальной переменной с другой, также
 категориальной переменной
 

# Статистические оценки

## Проверка на нормальность

1)  Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
#Первый вариант кода, который сделан до проведенной консультации (решила оставить оба)

shapiro_test_all <- function(data) {
  # Отбираем количественные переменные
  quant_vars <- names(data)[sapply(data, is.numeric) & names(data) != "id" & names(data) != "Age (days)"]

  # Проводим тест Шапиро-Уилка для каждой количественной переменной
  shapiro_results <- lapply(quant_vars, function(var) {
    # Отбираем 5000 значений из переменной
    sample_data <- sample(data[[var]], min(5000, length(data[[var]])), replace = TRUE)
    result <- shapiro.test(sample_data)
    c(result$p.value, result$statistic) 
  })

  # Преобразуем результаты в датафрейм
  shapiro_results <- data.frame(Variable = quant_vars,
                               p_value = sapply(shapiro_results, `[`, 1),
                               Shapiro_statistic = sapply(shapiro_results, `[`, 2))

  return(shapiro_results)
}

shapiro_results <- shapiro_test_all(cleaned_data)
shapiro_results$p_value <- round(shapiro_results$p_value, 4)
shapiro_results$Shapiro_statistic <- round(shapiro_results$Shapiro_statistic, 4)

 shapiro_results%>%
 flextable() %>%
  theme_box() %>%
  align(align = "center", part = "all")

```

Тест Шапиро-Уилка чувствителен к отклонениям от нормального распределения. Если p-value <= 0.05, то достаточно оснований для отклонения нулевой гипотезы о нормальном распределении, переменная вероятно не является нормально распределенной. Полученные p-value намного меньше 0.05, поэтому с большой степенью вероятности можно сказать, что данные не соответствуют нормальному распределению.

```{r}
# Второй вариант кода, сделан после проведенной консультации

cleaned_data %>%
  select(where(is.numeric), -`Age (days)`, -id) %>% 
  
  sapply(function(x) {
    sample_x <- sample(x, min(5000, length(x))) 
    shapiro.test(sample_x)$p.value < 0.05  
  }) %>%
  
  enframe() %>%
  
  mutate(across(value, function(x) ifelse(x == TRUE, "Распределение отлично от нормального", "Распределение нормальное"))) %>%
  rename(Variable = name) %>%
  rename(Distribution = value) 

```


2)  Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}

quant_vars <- c("Age (years)", "Height (cm)", "Weight (kg)", "Systolic blood pressure", "Diastolic blood pressure")

# Функция для построения QQ-плота

plot_qq <- function(var_name) {
  ggplot(cleaned_data, aes(sample = .data[[var_name]]), na.rm = TRUE) + 
    stat_qq() +
    stat_qq_line() +
    labs(title = paste0("QQ-график для ", var_name))+
    theme_bw()
}

# Строим QQ-плоты для каждой переменной

lapply(quant_vars, plot_qq)

```

В тесте Шапиро-Уилка мы получили p-value значительно меньше 0.05. Это указывало на то, что данные не соответствуют нормальному распределению. QQ-плоты подтверждают результаты теста. На большинстве плотов точки отклоняются от прямой линии, что указывает на не нормальное распределение. Но видим, что у переменных Height и в меньшей степени Weight все не так плохо, и они больше приближены к нормальному распределению. В идеале лучше использовать и тест Шапиро-Уилка, и QQ-плоты, чтобы получить более полное представление о распределении данных. QQ-плоты особенно полезны для визуального анализа отклонений от нормальности. Тест Шапиро-Уилка дает количественную оценку соответствия данных нормальному распределению.

3)  Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Напишите текст здесь**

1.  Тест Колмогорова-Смирнова (Kolmogorov-Smirnov test):

Принцип: Сравнивает эмпирическое распределение данных с теоретическим нормальным распределением. Ограничения: Более чувствителен к отклонениям в хвостах распределения, чем в центральной части. Может быть слишком строгим для малых выборок. Не подходит для проверки нормальности в случае наличия группирующих переменных (например, для разных групп пациентов).

2.  Тест Андерсона-Дарлинга (Anderson-Darling test):

Принцип: Сравнивает эмпирическое распределение с теоретическим, при этом большее внимание уделяется хвостам распределения. Ограничения: Чувствителен к выбросам. Может быть слишком строгим для малых выборок. Не подходит для проверки нормальности в случае наличия группирующих переменных.

3.  Критерий хи-квадрат (Chi-square test):

Принцип: Сравнивает эмпирические частоты с теоретическими частотами нормального распределения в разбитых интервалах. Ограничения: Требует большого размера выборки. Чувствителен к выбору интервалов. Не подходит для проверки нормальности в случае наличия группирующих переменных.

4.  Графический анализ (Histograms, Boxplots):

Принцип: Визуальная оценка распределения данных с помощью гистограмм и боксплотов. Ограничения: Субъективный метод. Не дает количественной оценки соответствия данных нормальному распределению. Может быть трудно интерпретировать для малых выборок.


## Сравнение групп

1)  Сравните группы (переменная **cardio**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}

# Сравнение групп по категориальным переменным. 

#Не могу пока преодолеть привычку использовать непараметрические тесты, когда данные распределены ненормально, поэтому сначала тест Манна-Уитни

cleaned_data %>%
  select(where(is.numeric), -`Age (days)`, -id) %>% 
  
  names() %>%
  set_names() %>%
  map(function(x) wilcox.test(cleaned_data[[x]] ~ cleaned_data$"Cardiovascular disease")$p.value < 0.05) %>%
  enframe() %>%
  unnest() %>%
  
  mutate(across(value, function(x) ifelse(value == TRUE, "Различие между группами есть", "Различие между группами не доказано"))) %>%
  
  filter(value == "Различие между группами есть") %>%
  rename(`Quantitative variable` = name) %>%
  rename(`Wilcox test result` = value)

```


```{r}
#Тем не менее, на таких данных можно использовать и параметрический t.test, поэтому сделала и его тоже. Результат не отличается, но тест более точный.

cleaned_data %>%
  select(where(is.numeric), -`Age (days)`, -id) %>% 
  
  names() %>%
  set_names() %>%
  map(function(x) t.test(cleaned_data[[x]] ~ cleaned_data$"Cardiovascular disease")$p.value < 0.05) %>%
  enframe() %>%
  unnest() %>%
  
  mutate(across(value, function(x) ifelse(value == TRUE, "Различие между группами есть", "Различие между группами не доказано"))) %>%
  
  filter(value == "Различие между группами есть") %>%
  rename(`Quantitative variable` = name) %>%
  rename(`T-test result` = value)

```

```{r}

# Сравнение групп по категориальным переменным. Тест Фишера не тянет такой большой датасет, поэтому тест Хи-квадрат. 

cleaned_data %>%
  select(where(is.factor), -`Cardiovascular disease`) %>% 
  
  names() %>%
  set_names() %>%
  map(function(x) {
    table_data <- table(cleaned_data[[x]], cleaned_data$"Cardiovascular disease") # Создаем таблицу соответствий
    chisq.test(table_data)$p.value < 0.05 
  }) %>%
  enframe() %>%
  unnest(cols = c(value)) %>%
  
  mutate(across(value, function(x) ifelse(x == TRUE, "Различие между группами есть", "Различие между группами не доказано"))) %>%
  
  filter(value == "Различие между группами есть") %>%
  rename(`Categorical variable` = name) %>%
  rename(`Сhi-square test result` = value) 

#Значимые различия обнаружены по всем переменным, кроме Alcohol intake 

```

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1)  Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}
#Первый вариант, сделан до проведенной консультации.

quant_vars <- c("Age (years)", "Height (cm)", "Weight (kg)", "Systolic blood pressure", "Diastolic blood pressure")

cleaned_data_no_NA <- cleaned_data[complete.cases(cleaned_data[quant_vars]), ]

correlation_matrix <- cor(cleaned_data_no_NA[quant_vars])

corrplot(correlation_matrix, method = "color", type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.7)

```

```{r, fig.height=10, fig.width=10}

#Второй вариант, сделан после консультации

cleaned_data %>%
  select(where(is.numeric), -`Age (days)`, -id) %>%
  corr.test(method = "spearman") -> corr_data

ggcorrplot(corr_data$r, p.mat = corr_data$p, insig = "blank", lab = TRUE)

```


## Моделирование

1)  Постройте регрессионную модель для переменной **cardio**. Опишите процесс построения

```{r}

#Так как cardiovascular_disease — это бинарная переменная (да/нет), мы будем использовать логистическую регрессию glm() с аргументом family = binomial.


cleaned_data %>% 
  select(!id, -`Age (days)`) %>%
  mutate(across(where(is.factor), function(x) x %>% fct_relabel(function(x) x %>% str_c(": ", .)))) -> model_data
  
glm(`Cardiovascular disease` ~ ., model_data, family = binomial) %>%
  
  tidy(conf.int = TRUE) %>%
  
  mutate(across(c(estimate, std.error, statistic, conf.low, conf.high), function(x) x %>% formatC(format = "f", digits = 2, decimal.mark = ".")),
         `p.value` = ifelse(`p.value` < 0.001, "<0.001", round(`p.value`, 3)),
         term = term %>% str_remove_all("`") %>% str_replace("\\(Intercept\\)", "Intercept")) %>%
  
  unite("95% CI", conf.low, conf.high, sep = ", ") %>%
  
  rename(`Переменная` = term, `Коэффициент` = estimate, `Стд.ошибка` = std.error, `Статистика` = statistic) %>%
  relocate(`95% CI`, .after = `Коэффициент`) %>%
  
  flextable() %>%
  theme_box() %>%
  align(align = "center", part = "all") %>%
  bold(i = ~`p.value` %>% str_extract("\\d.\\d{3}") %>% as.numeric() %>% `<`(0.05), j = "p.value") %>%
  
  color(i = ~`Коэффициент` > 0 & `p.value` %>% str_extract("\\d.\\d{3}") %>% as.numeric() %>% `<`(0.05), color = "green", j = "Коэффициент") %>%
  color(i = ~`Коэффициент` < 0 & `p.value` %>% str_extract("\\d.\\d{3}") %>% as.numeric() %>% `<`(0.05), color = "red", j = "Коэффициент")

```
